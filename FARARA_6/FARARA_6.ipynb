{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from scipy.io.wavfile import write\n",
    "from IPython.core.display import HTML, display\n",
    "from __future__ import division\n",
    "from matplotlib import style\n",
    "style.use(\"ggplot\")\n",
    "\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "#import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sp.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# play functions in iPython notebook\n",
    "try:\n",
    "    from IPython.display import Audio\n",
    "    def wavPlayer(data, rate):\n",
    "        display(Audio(data, rate=rate))\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Intializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# laod soundfiles.\n",
    "s1 = np.fromfile('sound1.dat', dtype=float, sep='\\n')\n",
    "s2 = sp.fromfile('sound2.dat', dtype=float, sep='\\n')\n",
    "\n",
    "#create random noise\n",
    "std = np.std(s1)\n",
    "size = s1.shape[0]\n",
    "s3 = np.random.normal(0,std,size)\n",
    "s4 = np.random.laplace(0,1,size)\n",
    "#stack\n",
    "s = sp.stack((s1, s2, s3))\n",
    "slap = sp.stack((s1,s2,s4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# random nxn mixing matrix\n",
    "A = sp.random.randint(1, high=11, size=9)\n",
    "A = A.reshape((3,3))\n",
    "A = A + sp.eye(3)\n",
    "\n",
    "# compute true W\n",
    "W_true = sp.linalg.inv(A)\n",
    "\n",
    "print('A:')\n",
    "print(A)\n",
    "print('W_true:')\n",
    "print(W_true)\n",
    "print(sp.linalg.det(W_true))\n",
    "\n",
    "x = sp.dot(A, s)\n",
    "sp.io.wavfile.write('mixed1' + '.wav', 8192, x[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove structure\n",
    "idx = sp.random.permutation(18000)\n",
    "x_shuffled = x[: , idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#center to zero mean\n",
    "x_mean = sp.mean(x_shuffled, axis=1).reshape((x.shape[0], 1))\n",
    "print('Mean of audio signals:')\n",
    "print(x_mean.shape)\n",
    "\n",
    "# center shuffled data\n",
    "x_shuffled_centered = x_shuffled - x_mean\n",
    "\n",
    "# center unshuffled data\n",
    "x_centered = x - x_mean\n",
    "print (x_centered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rand vals. for unmixing\n",
    "W = sp.random.randint(1, high=2, size=9)\n",
    "W = W.reshape((3,3)) * 0.1\n",
    "W = W + sp.eye(3) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define natural gradient with learning rate eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ICA_natural_gradient(W, x):\n",
    "    gradient = sp.concatenate((sp.dot(W, x), sp.dot(W, x)), axis=1)\n",
    "    gradient = sp.concatenate((gradient,sp.dot(W,x)), axis=1)\n",
    "    gradient = sp.special.expit(gradient) * 2\n",
    "    gradient = sp.ones((gradient.shape)) - gradient\n",
    "\n",
    "    gradient = (gradient * x)\n",
    "    normalization = sp.dot(W.T, W)\n",
    "\n",
    "    gradient = sp.dot(gradient, normalization)\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ICA(W, x, n=0.0085, l=0.9):\n",
    "    vals = []\n",
    "    t = 1\n",
    "    rate = n\n",
    "    for _ in range(3):\n",
    "            for i in range(x.shape[1]):\n",
    "                # adaptive learning rate !? --> bad results and not wanted\n",
    "                rate = rate*l\n",
    "                \n",
    "                # select random datapoint\n",
    "                #idx = sp.random.randint(0, high=18000, size=1)\n",
    "                #datapoint = x[:, idx].reshape((2,1))\n",
    "                \n",
    "                # choose next datapoint\n",
    "                datapoint = x[:, i].reshape((3,1))\n",
    "                \n",
    "                gradient = 0\n",
    "                gradient = ICA_natural_gradient(W, datapoint)\n",
    "                W = W + rate * gradient\n",
    "                \n",
    "                if (t % 1000) == 0:\n",
    "                    val = sp.sum((rate * gradient) ** 2)\n",
    "                    vals.append(val)\n",
    "                \n",
    "                t = t + 1\n",
    "    return W, vals\n",
    "\n",
    "def unmix_sources(W, x):\n",
    "    return sp.dot(W, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do things for normal dist\n",
    "# for unshuffled data\n",
    "W_un, vals_regular = ICA(sp.copy(W), x_centered)\n",
    "s_un= unmix_sources(W_un, x_centered)\n",
    "\n",
    "# for shuffled data\n",
    "W_shuffled, vals_shuffled = ICA(sp.copy(W), x_shuffled_centered)\n",
    "s_shuffled = unmix_sources(W_shuffled, x_shuffled_centered)\n",
    "\n",
    "\n",
    "print('W_natural (W learned from unshuffled data:')\n",
    "print(W_un)\n",
    "\n",
    "print('W_natural_shuffled (W learned from shuffled data:')\n",
    "print(W_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_and_play_data(data, title, label1, label2, label3):\n",
    "    sp.io.wavfile.write(label1 + '.wav', 8192, data[0, :])\n",
    "    sp.io.wavfile.write(label2 + '.wav', 8192, data[1, :])\n",
    "    sp.io.wavfile.write(label3 + '.wav', 8192, data[2, :])\n",
    "    print(label1 + ':')\n",
    "    wavPlayer(data[0, :], 8192)\n",
    "    print(label2 + ':')\n",
    "    wavPlayer(data[1, :], 8192)\n",
    "    print(label3 + ':')\n",
    "    wavPlayer(data[2, :], 8192)\n",
    "    \n",
    "    # plot data\n",
    "    x_axis = sp.arange(data.shape[1])\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(x_axis, data[1,:], 'b-', label=label2, alpha=0.5)\n",
    "    plt.plot(x_axis, data[0,:], 'r-', label=label1, alpha=0.5)\n",
    "    plt.plot(x_axis, data[2,:], 'g-', label=label3, alpha=0.5)\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), ncol=1)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('sound')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (i) Plot & Play the original sources\n",
    "#plot_and_play_data(s, 'Original sounds (sources)', 'sound 1', 'sound 2','sound 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (ii) Plot & Play the mixed sources before the data permutation\n",
    "#plot_and_play_data(x, 'Mixes sounds - before permutation', 'observation 1', 'observation 2','observation 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (iii) Plot & Play the mixed sources after the data permuta#tion\n",
    "#plot_and_play_data(x_shuffled, 'Mixes sounds - after permutation', 'observation 1 (shuffled)', 'observation 2 (shuffeld)','observation 3(shuffeled)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (iv) Plot & Play the recovered signals using the unpermuted data\n",
    "plot_and_play_data(s_un, 'recovered sounds - natural gradient', 'source 1 (natural estim.)', 'source 2 (natural estim.)','source 3 (natural estim.)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do things for laplacian dist\n",
    "# for unshuffled data\n",
    "W_un_lap, vals_lap = ICA(sp.copy(W), x_centered)\n",
    "s_un_lap= unmix_sources(W_un_lap, x_centered)\n",
    "\n",
    "# for shuffled data\n",
    "W_shuff_lap, vals_shuffled = ICA(sp.copy(W), x_shuffled_centered)\n",
    "s_shuff_lap = unmix_sources(W_shuff_lap, x_shuffled_centered)\n",
    "\n",
    "\n",
    "print('W_natural (W learned from unshuffled data:')\n",
    "print(W_un_lap)\n",
    "\n",
    "print('W_natural_shuffled (W learned from shuffled data:')\n",
    "print(W_shuff_lap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (iv) Plot & Play the recovered signals using the unpermuted data\n",
    "plot_and_play_data(s_un_lap, 'recovered sounds - natural gradient', 'source 1 (natural estim.)', 'source 2 (natural estim.)','source 3 (natural estim.)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (iv) Plot & Play the recovered signals using the permuted data\n",
    "plot_and_play_data(s_shuff_lap, 'recovered sounds - natural gradient', 'source 1 (natural estim.)', 'source 2 (natural estim.)','source 3 (natural estim.)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from numpy.linalg import eigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DataSets=scipy.io.loadmat('distrib.mat')\n",
    "Normal=DataSets['normal']\n",
    "Uniform=DataSets['uniform']\n",
    "Laplacian=DataSets['laplacian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(a) Apply the following mixing matrix A to the original data s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A=np.reshape([4,3,2,1],(2,2))\n",
    "MixN=np.dot(A,Normal)\n",
    "MixU=np.dot(A,Uniform)\n",
    "MixL=np.dot(A,Laplacian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(b) Center the mixed data to zero mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Center_N=(MixN.T-MixN.mean(axis=1)).T\n",
    "Center_U=(MixU.T-MixU.mean(axis=1)).T\n",
    "Center_L=(MixL.T-MixL.mean(axis=1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (c) Decorrelate the data by applying principal component analysis (PCA) and project them onto\n",
    "# the principal components (PCs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PCA(data):\n",
    "    Cov=np.cov(data)\n",
    "    E,V=eigh(Cov)\n",
    "    key = np.argsort(E)[::-1]\n",
    "    E, V = E[key], V[:, key]\n",
    "    NewData=np.dot(data.T,V)\n",
    "    return E,V,NewData.T\n",
    "    \n",
    "E_N,V_N,NewData_N=PCA(Center_N)\n",
    "E_U,V_U,NewData_U=PCA(Center_U)\n",
    "E_L,V_L,NewData_L=PCA(Center_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(d) Scale the data to unit variance in each PC direction (now the data is whitened or sphered)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Scale_N=(NewData_N.T/np.std(NewData_N,axis=1)).T\n",
    "Scale_U=(NewData_U.T/np.std(NewData_U,axis=1)).T\n",
    "Scale_L=(NewData_L.T/np.std(NewData_L,axis=1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (e) Rotate the data by different angles θ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "angelList=np.linspace(0,2*np.pi,100)\n",
    "def Rotataion(data,angelList):\n",
    "    for angel in angelList:\n",
    "        r=np.reshape([np.cos(angel),-np.sin(angel),np.sin(angel),np.cos(angel)],(2,2))\n",
    "        x=np.dot(r,data)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(f) Find the minimum and maximum kurtosis value for the first dimension and rotate the data\n",
    "# accordingly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the original dataset (sources) and the mixed dataset after the steps (a), (b), (c), (d),\n",
    "# and (f) as a scatter plot and display the respective marginal histograms. For step (e) plot\n",
    "# the kurtosis value as a function of angle for each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dplot(data1,data2,data3,title):\n",
    "    plt.figure(figsize=(15,5))    \n",
    "    axScatter=plt.subplot(131)\n",
    "    divider = make_axes_locatable(axScatter)\n",
    "    axHistx = divider.append_axes(\"top\", 1.5, pad=0.1, sharex=axScatter)\n",
    "    axHistx.set_title('Normal')\n",
    "    axHisty = divider.append_axes(\"right\", 1.5, pad=0.1, sharey=axScatter)\n",
    "    plt.setp(axHistx.get_xticklabels() + axHisty.get_yticklabels(),visible=False)\n",
    "    axScatter.scatter(data1[0], data1[1])\n",
    "    binwidth = 0.25\n",
    "    xymax = np.max([np.max(np.fabs(data1[0])), np.max(np.fabs(data1[1]))])\n",
    "    lim = (int(xymax/binwidth) + 1)*binwidth\n",
    "    bins = np.arange(-lim, lim + binwidth, binwidth)\n",
    "    axHistx.hist(data1[0],bins=bins)\n",
    "    axHisty.hist(data1[1],bins=bins, orientation='horizontal')\n",
    "    \n",
    "    axScatter=plt.subplot(132)\n",
    "    divider = make_axes_locatable(axScatter)\n",
    "    axHistx = divider.append_axes(\"top\", 1.5, pad=0.1, sharex=axScatter)\n",
    "    axHisty = divider.append_axes(\"right\", 1.5, pad=0.1, sharey=axScatter)\n",
    "    axHistx.set_title('Uniform')\n",
    "    plt.setp(axHistx.get_xticklabels() + axHisty.get_yticklabels(),visible=False)\n",
    "    axScatter.scatter(data2[0], data2[1])\n",
    "    axScatter.set_xlabel(title,fontsize=14, color='red')\n",
    "    binwidth = 0.25\n",
    "    xymax = np.max([np.max(np.fabs(data2[0])), np.max(np.fabs(data2[1]))])\n",
    "    lim = (int(xymax/binwidth) + 1)*binwidth\n",
    "    bins = np.arange(-lim, lim + binwidth, binwidth)\n",
    "    axHistx.hist(data2[0],bins=bins)\n",
    "    axHisty.hist(data2[1],bins=bins, orientation='horizontal')\n",
    "    \n",
    "    axScatter=plt.subplot(133)\n",
    "    divider = make_axes_locatable(axScatter)\n",
    "    axHistx = divider.append_axes(\"top\", 1.5, pad=0.1, sharex=axScatter)\n",
    "    axHisty = divider.append_axes(\"right\", 1.5, pad=0.1, sharey=axScatter)\n",
    "    axHistx.set_title('Laplacian')\n",
    "    plt.setp(axHistx.get_xticklabels() + axHisty.get_yticklabels(),visible=False)\n",
    "    axScatter.scatter(data3[0], data3[1])\n",
    "    binwidth = 0.5\n",
    "    xymax = np.max([np.max(np.fabs(data3[0])), np.max(np.fabs(data3[1]))])\n",
    "    lim = (int(xymax/binwidth) + 1)*binwidth\n",
    "    bins = np.arange(-lim, lim + binwidth, binwidth)\n",
    "    axHistx.hist(data3[0],bins=bins)\n",
    "    axHisty.hist(data3[1],bins=bins, orientation='horizontal')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dplot(Normal,Uniform,Laplacian,'Original Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dplot(MixN,MixU,MixL,'Mixed Data after a step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dplot(Center_N,Center_U,Center_L,'Center Data after b step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dplot(NewData_N,NewData_U,NewData_L,'Data after PCA after c step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dplot(Scale_N,Scale_U,Scale_L,'Scale Data after d step')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
